[{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"author-information","dir":"Articles","previous_headings":"","what":"Author Information","title":"Example_analysis","text":"Sunan Gao Johns Hopkins University Bloomberg School Public Health sgao57@jh.edu","code":""},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"the-package-i-choose-","dir":"Articles","previous_headings":"","what":"The package I choose.","title":"Example_analysis","text":"Package: bkmr","code":"library(bkmr) #> For guided examples, go to 'https://jenfb.github.io/bkmr/overview.html'"},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"research-question","dir":"Articles","previous_headings":"The package I choose.","what":"Research Question","title":"Example_analysis","text":"cost distribution different variables. association Room board Tuition -state residents (Total cost). Try use Bayesian kernel machine regression explore unlinear assocition multivariables cost.","code":""},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"original-data","dir":"Articles","previous_headings":"The package I choose.","what":"Original Data","title":"Example_analysis","text":"Data downloaded TidyTuesday. data week comes many different sources originally came US Department Education. Tuition fees college/university 2018-2019, along school type, degree length, state, -state vs --state Chronicle Higher Education. Data Source","code":""},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"data-dictionary","dir":"Articles","previous_headings":"The package I choose.","what":"Data Dictionary","title":"Example_analysis","text":"data dictionary column names mean:   data dictionary","code":""},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"load-the-data-into-r","dir":"Articles","previous_headings":"The package I choose.","what":"Load the data into R","title":"Example_analysis","text":"Download example data github save local site.  #### BKMR Model Using reference","code":"if (!require(\"tidyverse\", quietly = TRUE)) {     install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\") } #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.2     ✔ readr     2.1.4 #> ✔ forcats   1.0.0     ✔ stringr   1.5.0 #> ✔ ggplot2   3.4.3     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0 #> ✔ purrr     1.0.2      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors  if (!require(\"tidytuesdayR\", quietly = TRUE)) {     install.packages(\"tidytuesdayR\", repos = \"http://cran.us.r-project.org\") }  if (!require(\"here\", quietly = TRUE)) {     install.packages(\"here\", repos = \"http://cran.us.r-project.org\") } #> here() starts at /Users/gsn/Desktop/2023-2024/【JHU】Term-2/【Core】Statistical Programming Workflow/bkmr  if (!require(\"ggplot2\", quietly = TRUE)) {     install.packages(\"ggplot2\", repos = \"http://cran.us.r-project.org\") }  if (!require(\"purrr\", quietly = TRUE)) {     install.packages(\"purrr\", repos = \"http://cran.us.r-project.org\") } library(here) library(purrr)  ## Test if a directory named data exists locally. If it does not, write an R function that creates it programmatically. Saves the data only once if (!file.exists(here(\"data\", \"tuesdata_tution_cost.csv\"))) {          tuesdata <- tidytuesdayR::tt_load('2020-03-10')     tuition_cost <- tuesdata$tuition_cost     tuition_income <- tuesdata$tuition_income               save_directory <- here(\"data\") # File for saving data, must be created     if (!dir.exists(save_directory)) {       dir.create(save_directory, recursive = TRUE)     }          # save the files to csv objects ()     write.csv(tuesdata$tuition_cost, file = here(\"data\", \"tuesdata_tuition_cost.csv\"))     write.csv(tuesdata$tuition_income, file = here('data', 'tuesdata_tuition_income.csv'))      } #> --- Compiling #TidyTuesday Information for 2020-03-10 ---- #> --- There are 5 files available --- #> --- Starting Download --- #>  #>  Downloading file 1 of 5: `diversity_school.csv` #>  Downloading file 2 of 5: `historical_tuition.csv` #>  Downloading file 3 of 5: `salary_potential.csv` #>  Downloading file 4 of 5: `tuition_cost.csv` #>  Downloading file 5 of 5: `tuition_income.csv` #> --- Download complete --- ## Read in the data locally each time you knit/render tuition_cost <- read.csv(here(\"data\", \"tuesdata_tuition_cost.csv\")); tuition_cost$X = NULL tuition_income <- read.csv(here(\"data\", \"tuesdata_tuition_income.csv\")); tuition_income$X = NULL library(tidyverse) library(stringr)  # 1. Start with tuition cost dataset and drop any rows with NAs. tuition_cost <- tuition_cost %>%   drop_na()  # 2. Convert the state names (character strings) to all upper case. tuition_cost <- tuition_cost %>%   mutate(state = str_to_upper(state))  # 3. Create new column titled state_code_type that combines the state_code and school type into one column separated by “-”. (e.g. “TX-Private”). tuition_cost <- tuition_cost %>%   unite(state_code_type, state_code, type, sep = '-') # calculate the distribution of room and board of different schooles tuition_cost_summary <- tuition_cost %>%    group_by(state_code_type) %>%   summarise(     mean_room_and_board = mean(room_and_board),     sd_room_and_board = sd(room_and_board))  head(tuition_cost_summary) #> # A tibble: 6 × 3 #>   state_code_type mean_room_and_board sd_room_and_board #>   <chr>                         <dbl>             <dbl> #> 1 AK-Private                    6500              1131. #> 2 AK-Public                    10832.             2070. #> 3 AL-Private                    8800.             2366. #> 4 AL-Public                     6994.             2815. #> 5 AR-Private                    8147.             1670. #> 6 AR-Public                     7315.             2024. # calculate the distribution of body mass of penguins tuition_cost_summary2 <- tuition_cost %>%    select(-room_and_board) %>%   group_by(state_code_type, degree_length) %>%   summarise(     mean_in = mean(in_state_tuition),     sd_mass = sd(in_state_tuition)) #> `summarise()` has grouped output by 'state_code_type'. You can override using #> the `.groups` argument.  head(tuition_cost_summary2) #> # A tibble: 6 × 4 #> # Groups:   state_code_type [4] #>   state_code_type degree_length mean_in sd_mass #>   <chr>           <chr>           <dbl>   <dbl> #> 1 AK-Private      4 Year         15065    8153. #> 2 AK-Public       2 Year          4300      NA  #> 3 AK-Public       4 Year          7622.    501. #> 4 AL-Private      4 Year         18896.   8853. #> 5 AL-Public       2 Year          5433.   1758. #> 6 AL-Public       4 Year         10805.    920. # combine the observed data and summarized result tuition_cost_combined <- left_join(tuition_cost, tuition_cost_summary, 'state_code_type') head(tuition_cost_combined) #>                                   name      state state_code_type degree_length #> 1         Abilene Christian University      TEXAS      TX-Private        4 Year #> 2 Abraham Baldwin Agricultural College    GEORGIA       GA-Public        2 Year #> 3            Academy of Art University CALIFORNIA   CA-For Profit        4 Year #> 4               Adams State University   COLORADO       CO-Public        4 Year #> 5                   Adelphi University   NEW YORK      NY-Private        4 Year #> 6         Adirondack Community College   NEW YORK       NY-Public        2 Year #>   room_and_board in_state_tuition in_state_total out_of_state_tuition #> 1          10350            34850          45200                34850 #> 2           8474             4128          12602                12550 #> 3          16648            27810          44458                27810 #> 4           8782             9440          18222                20456 #> 5          16030            38660          54690                38660 #> 6          11660             5375          17035                 9935 #>   out_of_state_total mean_room_and_board sd_room_and_board #> 1              45200            9228.690          3037.913 #> 2              21024            9383.154          1844.827 #> 3              44458           13824.000          3993.739 #> 4              29238            9853.188          2384.372 #> 5              54690           11868.307          4704.870 #> 6              21595           12582.260          2289.362 tuition_cost_combined %>%    ggplot(aes(x = room_and_board, y = in_state_total)) +    geom_point(aes(x = room_and_board, y = in_state_total),  linetype = \"solid\", color = rainbow(1861), size = 1) +    labs(title = \"Association between the Room and board and total tution in state\",        subtitle = 'Point Chart: Room and board (USD) ~ Total tution (USD)',        caption = \"Data from the Chronicle of Higher Education\",        x = \"Room and board in (USD)\", y = \"Total tution (USD)\") +    facet_wrap(~degree_length, ncol = NULL, scales = \"free_y\") +   theme_minimal() tuition_cost_combined %>%    group_by(state) %>%    filter(room_and_board>10000) %>%   mutate(Mean_diff = out_of_state_total - mean(out_of_state_total)) %>%   ggplot(aes(x = state, y = Mean_diff)) +    geom_histogram(stat = \"identity\", fill = rainbow(931)) +    labs(title = \"The distribution of the total cost out of state difference in each state\",        subtitle = 'relative to the mean level at different state',        caption = \"Data from the Chronicle of Higher Education\",        x = \"State\", y = \"The difference bewteen mean value and observations in each group\") +   theme_minimal()+   theme(axis.text.x = element_text(angle = 45, hjust = 1, size=8)) library(bkmr) colnames(tuition_cost_combined) #>  [1] \"name\"                 \"state\"                \"state_code_type\"      #>  [4] \"degree_length\"        \"room_and_board\"       \"in_state_tuition\"     #>  [7] \"in_state_total\"       \"out_of_state_tuition\" \"out_of_state_total\"   #> [10] \"mean_room_and_board\"  \"sd_room_and_board\" data = tuition_cost_combined[, c('room_and_board',                                  'degree_length',                                   'mean_room_and_board',                                  'room_and_board',                                  'in_state_tuition',                                  'in_state_total',                                  'out_of_state_total',                                  'state')]  data_unique = unique(data[data$out_of_state_total < 20000,]) dat <- SimData(n = dim(data_unique)[1], M = 4) # introduce some nuisance data"},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"adopt-purrr-function-to-facilitate-process","dir":"Articles","previous_headings":"The package I choose. > Load the data into R","what":"Adopt purrr function to facilitate process","title":"Example_analysis","text":"","code":"## explore linear regression by_degree <- split(data_unique, data_unique$degree_length) by_degree |>   map(.f = ~ lm(out_of_state_total ~ state, data = .x)) |>   map(.f = coef) #> $`2 Year` #>         (Intercept)         stateALASKA        stateARIZONA       stateARKANSAS  #>          12548.5000           4751.5000            881.0714            744.8333  #>     stateCALIFORNIA       stateCOLORADO        stateGEORGIA          stateIDAHO  #>           2599.5000           2048.9000           2105.5000           3759.0000  #>           stateIOWA         stateKANSAS      stateLOUISIANA          stateMAINE  #>           1145.7500          -2841.7222           3875.5000           1621.5000  #>       stateMARYLAND       stateMICHIGAN      stateMINNESOTA    stateMISSISSIPPI  #>           5596.5000           1489.1667          -1316.3000          -2936.3571  #>       stateMISSOURI        stateMONTANA       stateNEBRASKA     stateNEW JERSEY  #>            886.9444           -569.2500          -1423.2500           2556.5000  #>     stateNEW MEXICO       stateNEW YORK   stateNORTH DAKOTA           stateOHIO  #>          -5693.2500           4952.3333            919.8333           3317.0000  #>       stateOKLAHOMA         stateOREGON   statePENNSYLVANIA stateSOUTH CAROLINA  #>           3427.0455           -253.1667           4746.5000           3824.0000  #>          stateTEXAS           stateUTAH     stateWASHINGTON  stateWEST VIRGINIA  #>          -1126.3276            -53.5000            944.0714           7351.5000  #>      stateWISCONSIN        stateWYOMING  #>           3015.7500           1762.9286  #>  #> $`4 Year` #>         (Intercept)         stateALASKA        stateARIZONA       stateARKANSAS  #>          17392.3333          -2392.3333          -5063.3333            675.0000  #>     stateCALIFORNIA        stateFLORIDA        stateGEORGIA         stateHAWAII  #>          -1894.3333           -411.9333          -1512.3333          -5246.3333  #>          stateIDAHO           stateIOWA         stateKANSAS       stateKENTUCKY  #>          -3677.3333           -207.3333         -15962.3333          -3337.3333  #>      stateLOUISIANA       stateMARYLAND       stateMICHIGAN      stateMINNESOTA  #>          -1136.3333           1607.6667          -6392.3333            374.3333  #>    stateMISSISSIPPI       stateMISSOURI        stateMONTANA       stateNEBRASKA  #>          -1951.4444            424.9167          -6072.3333           -353.5833  #>         stateNEVADA     stateNEW JERSEY     stateNEW MEXICO       stateNEW YORK  #>          -4484.3333            274.3333          -1376.3333          -2790.1410  #> stateNORTH CAROLINA   stateNORTH DAKOTA           stateOHIO       stateOKLAHOMA  #>           -194.7333          -1607.3333          -2355.3333          -2060.8333  #>         stateOREGON   statePENNSYLVANIA stateSOUTH CAROLINA   stateSOUTH DAKOTA  #>           1257.6667          -2942.3333           -279.3333           1733.6667  #>      stateTENNESSEE          stateTEXAS           stateUTAH        stateVERMONT  #>            719.1667          -1987.1111          -4144.3333            891.6667  #>       stateVIRGINIA  #>           1007.6667  ## transform data string_to_integer <- function(column) {   as.integer(as.factor(column)) } data_unique[, c(2,8)] <- map_dfc(.x = data_unique[, c(2,8)], .f = tolower) data_unique[, c(2,8)] <- map(data_unique[, c(2,8)], string_to_integer) set.seed(208) data_unique[,c(1:8)] = scale(data_unique[,c(1:8)])  y <- as.matrix(data_unique$out_of_state_total) Z <- cbind(as.matrix(data_unique[, c(1,2,8)],), dat$Z) X <- as.matrix(data_unique[, c(3)]) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 1000, verbose = FALSE, varsel = TRUE) #> Iteration: 100 (10% completed; 2.4747 secs elapsed) #> Iteration: 200 (20% completed; 4.84559 secs elapsed) #> Iteration: 300 (30% completed; 7.29754 secs elapsed) #> Iteration: 400 (40% completed; 9.66106 secs elapsed) #> Iteration: 500 (50% completed; 12.02762 secs elapsed) #> Iteration: 600 (60% completed; 14.48249 secs elapsed) #> Iteration: 700 (70% completed; 16.84234 secs elapsed) #> Iteration: 800 (80% completed; 19.19864 secs elapsed) #> Iteration: 900 (90% completed; 21.66073 secs elapsed) #> Iteration: 1000 (100% completed; 24.01741 secs elapsed) ExtractPIPs(fitkm) #>         variable   PIP #> 1 room_and_board 1.000 #> 2  degree_length 1.000 #> 3          state 0.662 #> 4             z1 0.326 #> 5             z2 0.516 #> 6             z3 0.000 #> 7             z4 0.096 # A posteriori inclusion probability in a simulated data set (the bigger the better) #TracePlot(fit = fitkm, par = \"r\", comp = 1) #TracePlot(fit = fitkm, par = \"sigsq.eps\")  pred.resp.univar <- PredictorResponseUnivar(fit = fitkm) library(ggplot2) ggplot(pred.resp.univar, aes(z, est, ymin = est - 1.96*se, ymax = est + 1.96*se)) +      geom_smooth(stat = \"identity\") +      facet_wrap(~ variable) +     labs(title = \"The univariate relationship between specific exposure and the total cost\",        subtitle = 'All variables have been standarized to 0~1',        caption = \"Data from the Chronicle of Higher Education\",        x = \"Scaled Value\", y = \"h(z)\")"},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"summary-of-analysis","dir":"Articles","previous_headings":"The package I choose.","what":"Summary of Analysis","title":"Example_analysis","text":"school California, New York, Massachusetts, Pennsylvania showed top 4 highest deviation total cost state. total tution state showed two kinds linear association room board. two patterns can detected explore . Even though considering nuisance parameter, BKMR identify actual effect room board cost, degree length state total cost state cost smaller 20000. Also, PIP value list, room board, degeree length state showed highest prbability, corrsponding expectations.","code":""},{"path":"https://sngao.github.io/bkmr/articles/Example_analysis.html","id":"functions-used-from-packages","dir":"Articles","previous_headings":"The package I choose.","what":"Functions used from packages","title":"Example_analysis","text":"dplyr: filter(); select(); summarise(); mutate(); group_by(); left_join() tidyr: drop_na(); unite() purrr: map_dfc(); map() ggplot2: geom_point(); geom_(); geom_histogram; geom_smooth, facet_wrap() bkmr: ExtractPIPs(); kmbayes(); PredictorResponseUnivar()","code":""},{"path":"https://sngao.github.io/bkmr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jennifer F. Bobb. Author, maintainer.","code":""},{"path":"https://sngao.github.io/bkmr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bobb J (2023). bkmr: Bayesian Kernel Machine Regression. https://github.com/jenfb/bkmr, https://sngao.github.io/bkmr/.","code":"@Manual{,   title = {bkmr: Bayesian Kernel Machine Regression},   author = {Jennifer F. Bobb},   year = {2023},   note = {https://github.com/jenfb/bkmr, https://sngao.github.io/bkmr/}, }"},{"path":"https://sngao.github.io/bkmr/index.html","id":"basic-information","dir":"","previous_headings":"","what":"Basic information","title":"Bayesian Kernel Machine Regression","text":"Title: BKMR Package Author: Jennifer F. Bobb Website Author: Sunan Gao Description: R package bkmr implements Bayesian kernel machine regression, statistical approach estimating joint health effects multiple concurrent exposures. Additional information statistical methodology computational details provided Bobb et al. 2015. recent extensions, details software, worked-examples provided Bobb et al. 2018. Original R package came Link Deployed Website Link","code":""},{"path":"https://sngao.github.io/bkmr/index.html","id":"customized-things-in-pkgdown-website","dir":"","previous_headings":"","what":"Customized things in pkgdown website","title":"Bayesian Kernel Machine Regression","text":"","code":"theme: breeze-light  # using the \"breeze-light\" theme   bslib:     bg: '#F5F5F5' # Specifies the background color for the website.     fg: '#B8BCC2' # Specifies the foreground (text) color for the website.     primary: '#306cc9' # Specifies the primary color used for links and other elements.   navbar:     bg: primary # Sets the background color of the navigation bar     structure:       left: search # Places a search bar on the left side of the navigation bar.       right:       - reference       - articles   footer:     structure:       left: developed_by # Specifies content on the left side of the footer       right: built_with # Specifies content on the right side of the footer"},{"path":"https://sngao.github.io/bkmr/index.html","id":"exported-function-list","dir":"","previous_headings":"Customized things in pkgdown website","what":"Exported function list","title":"Bayesian Kernel Machine Regression","text":"","code":"ComputePostmeanHnew():  #Compute the posterior mean and variance of h at a new predictor values  ExtractEsts(): #Extract summary statistics  ExtractPIPs(): #Extract posterior inclusion probabilities (PIPs) from BKMR model fit  ExtractSamps(): #Extract samples  InvestigatePrior(): #Investigate prior  OverallRiskSummaries(): #Calculate overall risk summaries  PlotPriorFits(): #Plot of exposure-response function from univariate KMR fit  PredictorResponseBivar(): #Predict the exposure-response function at a new grid of points  PredictorResponseBivarLevels(): #Plot cross-sections of the bivariate predictor-response function  PredictorResponseBivarPair(): #Plot bivariate predictor-response function on a new grid of points  PredictorResponseUnivar(): #Plot univariate predictor-response function on a new grid of points  SamplePred(): #Obtain posterior samples of predictions at new points SimData(): #Simulate dataset  SingVarIntSummaries(): #Single Variable Interaction Summaries  SingVarRiskSummaries(): #Single Variable Risk Summaries  TracePlot(): #Trace plot  kmbayes(): #Fit Bayesian kernel machine regression  print(<bkmrfit>): #Print basic summary of BKMR model fit  summary(<bkmrfit>): #Summarizing BKMR model fits"},{"path":"https://sngao.github.io/bkmr/index.html","id":"a-basic-example-with-one-of-the-functions-fitkm","dir":"","previous_headings":"","what":"A basic example with one of the functions (fitkm).","title":"Bayesian Kernel Machine Regression","text":"","code":"library(bkmr) library(ggplot2)  set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 10000, verbose = FALSE, varsel = TRUE) TracePlot(fit = fitkm, par = \"beta\") ggplot(pred.resp.univar, aes(z, est, ymin = est - 1.96*se, ymax = est + 1.96*se)) +      geom_smooth(stat = \"identity\") +      facet_wrap(~ variable) +   ylab(\"h(z)\")"},{"path":"https://sngao.github.io/bkmr/index.html","id":"install-instructions","dir":"","previous_headings":"","what":"Install instructions","title":"Bayesian Kernel Machine Regression","text":"can install latest released version bkmr CRAN : latest development version github : general overview guided examples, go https://jenfb.github.io/bkmr/overview.html. examples software paper, please see https://jenfb.github.io/bkmr/SimData1 https://jenfb.github.io/bkmr/ProbitEx","code":"install.packages(\"bkmr\") install.packages(\"devtools\") devtools::install_github(\"jenfb/bkmr\")"},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"Compute posterior mean variance h new predictor values","code":""},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"","code":"ComputePostmeanHnew(   fit,   y = NULL,   Z = NULL,   X = NULL,   Znew = NULL,   sel = NULL,   method = \"approx\" )"},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. Znew matrix new predictor values predict new h, row represents new observation. set NULL default using observed exposures Z. sel selects iterations MCMC sampler use inference; see details method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details","code":""},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"list length two containing posterior mean vector posterior variance matrix","code":""},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"method == \"approx\", argument sel defaults second half MCMC iterations. method == \"exact\", argument sel defaults keeping every 10 iterations dropping first 50% samples, results fewer 100 iterations, 100 iterations kept guided examples additional information, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/ComputePostmeanHnew.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the posterior mean and variance of h at a new predictor values — ComputePostmeanHnew","text":"","code":"set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.01262 secs elapsed) #> Iteration: 20 (20% completed; 0.01955 secs elapsed) #> Iteration: 30 (30% completed; 0.02596 secs elapsed) #> Iteration: 40 (40% completed; 0.03256 secs elapsed) #> Iteration: 50 (50% completed; 0.0389 secs elapsed) #> Iteration: 60 (60% completed; 0.04484 secs elapsed) #> Iteration: 70 (70% completed; 0.05077 secs elapsed) #> Iteration: 80 (80% completed; 0.06551 secs elapsed) #> Iteration: 90 (90% completed; 0.07103 secs elapsed) #> Iteration: 100 (100% completed; 0.07683 secs elapsed)  med_vals <- apply(Z, 2, median) Znew <- matrix(med_vals, nrow = 1) h_true <- dat$HFun(Znew) h_est1 <- ComputePostmeanHnew(fitkm, Znew = Znew, method = \"approx\") h_est2 <- ComputePostmeanHnew(fitkm, Znew = Znew, method = \"exact\")"},{"path":"https://sngao.github.io/bkmr/reference/ExtractEsts.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract summary statistics — ExtractEsts","title":"Extract summary statistics — ExtractEsts","text":"Obtain summary statistics parameter BKMR fit","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractEsts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract summary statistics — ExtractEsts","text":"","code":"ExtractEsts(fit, q = c(0.025, 0.25, 0.5, 0.75, 0.975), sel = NULL)"},{"path":"https://sngao.github.io/bkmr/reference/ExtractEsts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract summary statistics — ExtractEsts","text":"fit object containing results returned kmbayes function q vector quantiles sel logical expression indicating samples keep; defaults keeping second half samples","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractEsts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract summary statistics — ExtractEsts","text":"list component data frame containing summary statistics posterior distribution one parameters (vector parameters) estimated","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractEsts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract summary statistics — ExtractEsts","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.0053 secs elapsed) #> Iteration: 20 (20% completed; 0.01203 secs elapsed) #> Iteration: 30 (30% completed; 0.01818 secs elapsed) #> Iteration: 40 (40% completed; 0.03229 secs elapsed) #> Iteration: 50 (50% completed; 0.03793 secs elapsed) #> Iteration: 60 (60% completed; 0.04368 secs elapsed) #> Iteration: 70 (70% completed; 0.04981 secs elapsed) #> Iteration: 80 (80% completed; 0.05575 secs elapsed) #> Iteration: 90 (90% completed; 0.06187 secs elapsed) #> Iteration: 100 (100% completed; 0.06726 secs elapsed)  ests <- ExtractEsts(fitkm) names(ests) #> [1] \"sigsq.eps\" \"beta\"      \"lambda\"    \"r\"         ests$beta #>          mean         sd   q_2.5     q_25     q_50     q_75   q_97.5 #> beta 1.889308 0.08175852 1.72388 1.839835 1.889967 1.941782 2.046596"},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"Extract posterior inclusion probabilities (PIPs) Bayesian Kernel Machine Regression (BKMR) model fit","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"","code":"ExtractPIPs(fit, sel = NULL, z.names = NULL)"},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"fit object containing results returned kmbayes function sel logical expression indicating samples keep; defaults keeping second half samples z.names optional argument providing names variables included h function.","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"data frame variable-specific PIPs BKMR fit component-wise variable selection, group-specific conditional (within-group) PIPs BKMR fit hierarchical variable selection.","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractPIPs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior inclusion probabilities (PIPs) from BKMR model fit — ExtractPIPs","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00583 secs elapsed) #> Iteration: 20 (20% completed; 0.01253 secs elapsed) #> Iteration: 30 (30% completed; 0.02577 secs elapsed) #> Iteration: 40 (40% completed; 0.03097 secs elapsed) #> Iteration: 50 (50% completed; 0.03628 secs elapsed) #> Iteration: 60 (60% completed; 0.04157 secs elapsed) #> Iteration: 70 (70% completed; 0.04675 secs elapsed) #> Iteration: 80 (80% completed; 0.05224 secs elapsed) #> Iteration: 90 (90% completed; 0.0578 secs elapsed) #> Iteration: 100 (100% completed; 0.06347 secs elapsed)  ExtractPIPs(fitkm) #>   variable  PIP #> 1       z1 1.00 #> 2       z2 1.00 #> 3       z3 0.00 #> 4       z4 0.28"},{"path":"https://sngao.github.io/bkmr/reference/ExtractSamps.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract samples — ExtractSamps","title":"Extract samples — ExtractSamps","text":"Extract samples parameter BKMR fit","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractSamps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract samples — ExtractSamps","text":"","code":"ExtractSamps(fit, sel = NULL)"},{"path":"https://sngao.github.io/bkmr/reference/ExtractSamps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract samples — ExtractSamps","text":"fit object containing results returned kmbayes function sel logical expression indicating samples keep; defaults keeping second half samples","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractSamps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract samples — ExtractSamps","text":"list component contains posterior samples one parameters (vector parameters) estimated","code":""},{"path":"https://sngao.github.io/bkmr/reference/ExtractSamps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract samples — ExtractSamps","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00502 secs elapsed) #> Iteration: 20 (20% completed; 0.01183 secs elapsed) #> Iteration: 30 (30% completed; 0.0246 secs elapsed) #> Iteration: 40 (40% completed; 0.02984 secs elapsed) #> Iteration: 50 (50% completed; 0.03503 secs elapsed) #> Iteration: 60 (60% completed; 0.04056 secs elapsed) #> Iteration: 70 (70% completed; 0.04623 secs elapsed) #> Iteration: 80 (80% completed; 0.05236 secs elapsed) #> Iteration: 90 (90% completed; 0.05893 secs elapsed) #> Iteration: 100 (100% completed; 0.06505 secs elapsed)  samps <- ExtractSamps(fitkm)"},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":null,"dir":"Reference","previous_headings":"","what":"Investigate prior — InvestigatePrior","title":"Investigate prior — InvestigatePrior","text":"Investigate impact r[m] parameters smoothness exposure-response function h(z[m]).","code":""},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Investigate prior — InvestigatePrior","text":"","code":"InvestigatePrior(   y,   Z,   X,   ngrid = 50,   q.seq = c(2, 1, 1/2, 1/4, 1/8, 1/16),   r.seq = NULL,   Drange = NULL,   verbose = FALSE )"},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Investigate prior — InvestigatePrior","text":"y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. ngrid Number grid points plot exposure-response function q.seq Sequence values corresponding different degrees smoothness estimated exposure-response function. value q corresponds fractions range data decay correlation cor(h[],h[j]) two subjects 50%. r.seq sequence values fix r estimating exposure-response function Drange range z_m data apply values q.seq. specified, calculated maximum ranges z_1 z_M. verbose TRUE FALSE: flag indicating whether print screen exposure variable q value completed","code":""},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Investigate prior — InvestigatePrior","text":"list containing predicted values, residuals, estimated predictor-response function degree smoothness considered","code":""},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Investigate prior — InvestigatePrior","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/InvestigatePrior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Investigate prior — InvestigatePrior","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  priorfits <- InvestigatePrior(y = y, Z = Z, X = X, q.seq = c(2, 1/2, 1/4, 1/16)) PlotPriorFits(y = y, Z = Z, X = X, fits = priorfits)"},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate overall risk summaries — OverallRiskSummaries","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"Compare estimated h function predictors particular quantile second fixed quantile","code":""},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"","code":"OverallRiskSummaries(   fit,   y = NULL,   Z = NULL,   X = NULL,   qs = seq(0.25, 0.75, by = 0.05),   q.fixed = 0.5,   method = \"approx\",   sel = NULL )"},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. qs vector quantiles calculate overall risk summary q.fixed second quantile compare estimated h function method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details sel selects iterations MCMC sampler use inference; see details","code":""},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"data frame containing (posterior mean) estimate posterior standard deviation overall risk measures","code":""},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"method == \"approx\", argument sel defaults second half MCMC iterations. method == \"exact\", argument sel defaults keeping every 10 iterations dropping first 50% samples, results fewer 100 iterations, 100 iterations kept guided examples additional information, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/OverallRiskSummaries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate overall risk summaries — OverallRiskSummaries","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00538 secs elapsed) #> Iteration: 20 (20% completed; 0.01068 secs elapsed) #> Iteration: 30 (30% completed; 0.01618 secs elapsed) #> Iteration: 40 (40% completed; 0.02136 secs elapsed) #> Iteration: 50 (50% completed; 0.02654 secs elapsed) #> Iteration: 60 (60% completed; 0.0318 secs elapsed) #> Iteration: 70 (70% completed; 0.03693 secs elapsed) #> Iteration: 80 (80% completed; 0.04206 secs elapsed) #> Iteration: 90 (90% completed; 0.04749 secs elapsed) #> Iteration: 100 (100% completed; 0.06039 secs elapsed)  risks.overall <- OverallRiskSummaries(fit = fitkm, qs = seq(0.25, 0.75, by = 0.05),  q.fixed = 0.5, method = \"exact\")"},{"path":"https://sngao.github.io/bkmr/reference/PlotPriorFits.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","title":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","text":"Plot estimated h(z[m]) estimated frequentist KMR r[m] fixed specific values","code":""},{"path":"https://sngao.github.io/bkmr/reference/PlotPriorFits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","text":"","code":"PlotPriorFits(   y,   X,   Z,   fits,   which.z = NULL,   which.q = NULL,   plot.resid = TRUE,   ylim = NULL,   ... )"},{"path":"https://sngao.github.io/bkmr/reference/PlotPriorFits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","text":"y vector outcome data length n. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. fits output InvestigatePrior .z predictors (columns Z) plot .q q.values plot; defaults possible plot.resid whether plot data points ylim plotting limits y-axis ... plotting arguments","code":""},{"path":"https://sngao.github.io/bkmr/reference/PlotPriorFits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","text":"return value, generates plot","code":""},{"path":"https://sngao.github.io/bkmr/reference/PlotPriorFits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of exposure-response function from univariate KMR fit — PlotPriorFits","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  priorfits <- InvestigatePrior(y = y, Z = Z, X = X, q.seq = c(2, 1/2, 1/4, 1/16)) PlotPriorFits(y = y, Z = Z, X = X, fits = priorfits)"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"Predict exposure-response function new grid points","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"","code":"PredictorResponseBivar(   fit,   y = NULL,   Z = NULL,   X = NULL,   z.pairs = NULL,   method = \"approx\",   ngrid = 50,   q.fixed = 0.5,   sel = NULL,   min.plot.dist = 0.5,   center = TRUE,   z.names = colnames(Z),   verbose = TRUE,   ... )"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. z.pairs data frame showing pairs predictors plot method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details ngrid number grid points dimension q.fixed vector quantiles fix remaining predictors Z sel logical expression indicating samples keep; defaults keeping second half samples min.plot.dist specifies minimum distance new grid point needs observed data point order compute prediction; points computed center flag whether scale exposure-response function mean zero z.names optional vector names columns z verbose TRUE FALSE: flag whether print intermediate output screen ... arguments pass prediction function","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"long data frame name first predictor, name second predictor, value first predictor, value second predictor, posterior mean estimate, posterior standard deviation estimated exposure response function","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict the exposure-response function at a new grid of points — PredictorResponseBivar","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00486 secs elapsed) #> Iteration: 20 (20% completed; 0.01036 secs elapsed) #> Iteration: 30 (30% completed; 0.01556 secs elapsed) #> Iteration: 40 (40% completed; 0.02075 secs elapsed) #> Iteration: 50 (50% completed; 0.0259 secs elapsed) #> Iteration: 60 (60% completed; 0.03097 secs elapsed) #> Iteration: 70 (70% completed; 0.03613 secs elapsed) #> Iteration: 80 (80% completed; 0.0413 secs elapsed) #> Iteration: 90 (90% completed; 0.0469 secs elapsed) #> Iteration: 100 (100% completed; 0.06004 secs elapsed)  ## Obtain predicted value on new grid of points for each pair of predictors ## Using only a 10-by-10 point grid to make example run quickly pred.resp.bivar <- PredictorResponseBivar(fit = fitkm, min.plot.dist = 1, ngrid = 10) #> Pair 1 out of 6 #> Pair 2 out of 6 #> Pair 3 out of 6 #> Pair 4 out of 6 #> Pair 5 out of 6 #> Pair 6 out of 6"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"Function plot h function particular variable different levels (quantiles) second variable","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"","code":"PredictorResponseBivarLevels(   pred.resp.df,   Z = NULL,   qs = c(0.25, 0.5, 0.75),   both_pairs = TRUE,   z.names = NULL )"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"pred.resp.df object obtained running function PredictorResponseBivar Z n--M matrix predictor variables included h function. row represents observation column represents predictor. qs vector quantiles fix second variable both_pairs flag indicating whether, h(z1) plotted z2 fixed different levels, plotted reverse order well (h(z2) different levels z1) z.names optional vector names columns z","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"long data frame name first predictor, name second predictor, value first predictor, quantile second predictor fixed, posterior mean estimate, posterior standard deviation estimated exposure response function","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarLevels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot cross-sections of the bivariate predictor-response function — PredictorResponseBivarLevels","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00467 secs elapsed) #> Iteration: 20 (20% completed; 0.01003 secs elapsed) #> Iteration: 30 (30% completed; 0.01568 secs elapsed) #> Iteration: 40 (40% completed; 0.02103 secs elapsed) #> Iteration: 50 (50% completed; 0.02632 secs elapsed) #> Iteration: 60 (60% completed; 0.03226 secs elapsed) #> Iteration: 70 (70% completed; 0.03816 secs elapsed) #> Iteration: 80 (80% completed; 0.04338 secs elapsed) #> Iteration: 90 (90% completed; 0.04903 secs elapsed) #> Iteration: 100 (100% completed; 0.05425 secs elapsed)  ## Obtain predicted value on new grid of points for each pair of predictors ## Using only a 10-by-10 point grid to make example run quickly pred.resp.bivar <- PredictorResponseBivar(fit = fitkm, min.plot.dist = 1, ngrid = 10) #> Pair 1 out of 6 #> Pair 2 out of 6 #> Pair 3 out of 6 #> Pair 4 out of 6 #> Pair 5 out of 6 #> Pair 6 out of 6 pred.resp.bivar.levels <- PredictorResponseBivarLevels(pred.resp.df = pred.resp.bivar,  Z = Z, qs = c(0.1, 0.5, 0.9))"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarPair.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","title":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","text":"Plot bivariate predictor-response function new grid points","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarPair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","text":"","code":"PredictorResponseBivarPair(   fit,   y = NULL,   Z = NULL,   X = NULL,   whichz1 = 1,   whichz2 = 2,   whichz3 = NULL,   method = \"approx\",   prob = 0.5,   q.fixed = 0.5,   sel = NULL,   ngrid = 50,   min.plot.dist = 0.5,   center = TRUE,   ... )"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarPair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. whichz1 vector identifying first predictor (column Z) plotted whichz2 vector identifying second predictor (column Z) plotted whichz3 vector identifying third predictor set pre-specified fixed quantile (determined prob) method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details prob pre-specified quantile set third predictor (determined whichz3); defaults 0.5 (50th percentile) q.fixed vector quantiles fix remaining predictors Z sel logical expression indicating samples keep; defaults keeping second half samples ngrid number grid points cover range predictor (column Z) min.plot.dist specifies minimum distance new grid point needs observed data point order compute prediction; points computed center flag whether scale exposure-response function mean zero ... arguments pass prediction function","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarPair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","text":"data frame value first predictor, value second predictor, posterior mean estimate, posterior standard deviation","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseBivarPair.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bivariate predictor-response function on a new grid of points — PredictorResponseBivarPair","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00534 secs elapsed) #> Iteration: 20 (20% completed; 0.01063 secs elapsed) #> Iteration: 30 (30% completed; 0.01585 secs elapsed) #> Iteration: 40 (40% completed; 0.021 secs elapsed) #> Iteration: 50 (50% completed; 0.02623 secs elapsed) #> Iteration: 60 (60% completed; 0.03128 secs elapsed) #> Iteration: 70 (70% completed; 0.0363 secs elapsed) #> Iteration: 80 (80% completed; 0.04129 secs elapsed) #> Iteration: 90 (90% completed; 0.04633 secs elapsed) #> Iteration: 100 (100% completed; 0.0516 secs elapsed)  ## Obtain predicted value on new grid of points ## Using only a 10-by-10 point grid to make example run quickly pred.resp.bivar12 <- PredictorResponseBivarPair(fit = fitkm, min.plot.dist = 1, ngrid = 10)"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"Plot univariate predictor-response function new grid points","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"","code":"PredictorResponseUnivar(   fit,   y = NULL,   Z = NULL,   X = NULL,   which.z = 1:ncol(Z),   method = \"approx\",   ngrid = 50,   q.fixed = 0.5,   sel = NULL,   min.plot.dist = Inf,   center = TRUE,   z.names = colnames(Z),   ... )"},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. .z vector identifying predictors (columns Z) plotted method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details ngrid number grid points cover range predictor (column Z) q.fixed vector quantiles fix remaining predictors Z sel logical expression indicating samples keep; defaults keeping second half samples min.plot.dist specifies minimum distance new grid point needs observed data point order compute prediction; points computed center flag whether scale exposure-response function mean zero z.names optional vector names columns z ... arguments pass prediction function","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"long data frame predictor name, predictor value, posterior mean estimate, posterior standard deviation","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/PredictorResponseUnivar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot univariate predictor-response function on a new grid of points — PredictorResponseUnivar","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00509 secs elapsed) #> Iteration: 20 (20% completed; 0.01026 secs elapsed) #> Iteration: 30 (30% completed; 0.01535 secs elapsed) #> Iteration: 40 (40% completed; 0.15398 secs elapsed) #> Iteration: 50 (50% completed; 0.15915 secs elapsed) #> Iteration: 60 (60% completed; 0.16425 secs elapsed) #> Iteration: 70 (70% completed; 0.16931 secs elapsed) #> Iteration: 80 (80% completed; 0.17475 secs elapsed) #> Iteration: 90 (90% completed; 0.17993 secs elapsed) #> Iteration: 100 (100% completed; 0.18514 secs elapsed) pred.resp.univar <- PredictorResponseUnivar(fit = fitkm)"},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain posterior samples of predictions at new points — SamplePred","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"Obtains posterior samples E(Y) = h(Znew) + beta*Xnew g^{-1}[E(y)]","code":""},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"","code":"SamplePred(   fit,   Znew = NULL,   Xnew = NULL,   Z = NULL,   X = NULL,   y = NULL,   sel = NULL,   type = c(\"link\", \"response\"),   ... )"},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"fit object containing results returned kmbayes function Znew optional matrix new predictor values predict new h, row represents new observation. specified, defaults using observed Z values Xnew optional matrix new covariate values obtain predictions. specified, defaults using observed X values Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. y vector outcome data length n. sel vector selecting iterations BKMR fit retained inference. specified, default keeping every 10 iterations dropping first 50% samples, results fewer 100 iterations, 100 iterations kept type whether make predictions scale link response; relevant binomial outcome family ... arguments; currently used","code":""},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"matrix posterior samples new points","code":""},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/SamplePred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain posterior samples of predictions at new points — SamplePred","text":"","code":"set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00501 secs elapsed) #> Iteration: 20 (20% completed; 0.01037 secs elapsed) #> Iteration: 30 (30% completed; 0.0157 secs elapsed) #> Iteration: 40 (40% completed; 0.02098 secs elapsed) #> Iteration: 50 (50% completed; 0.02623 secs elapsed) #> Iteration: 60 (60% completed; 0.03146 secs elapsed) #> Iteration: 70 (70% completed; 0.03674 secs elapsed) #> Iteration: 80 (80% completed; 0.05001 secs elapsed) #> Iteration: 90 (90% completed; 0.05534 secs elapsed) #> Iteration: 100 (100% completed; 0.06062 secs elapsed)  med_vals <- apply(Z, 2, median) Znew <- matrix(med_vals, nrow = 1) h_true <- dat$HFun(Znew) set.seed(111) samps3 <- SamplePred(fitkm, Znew = Znew, Xnew = cbind(0)) head(samps3) #>           znew1 #> iter51 2.406482 #> iter52 1.934470 #> iter53 2.018921 #> iter54 1.440331 #> iter55 2.047760 #> iter56 1.907901"},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate dataset — SimData","title":"Simulate dataset — SimData","text":"Simulate predictor, covariate, continuous outcome data","code":""},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate dataset — SimData","text":"","code":"SimData(   n = 100,   M = 5,   sigsq.true = 0.5,   beta.true = 2,   hfun = 3,   Zgen = \"norm\",   ind = 1:2,   family = \"gaussian\" )"},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate dataset — SimData","text":"n Number observations M Number predictor variables generate sigsq.true Variance normally distributed residual error beta.true Coefficient covariate hfun integer 1 3 identifying predictor-response function generate Zgen Method generating matrix Z exposure variables, taking one values c(\"unif\", \"norm\", \"corr\", \"realistic\") ind select predictor(s) included h function; many predictors can included depend h function used. family description error distribution link function used model. Currently implemented gaussian binomial families.","code":""},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate dataset — SimData","text":"list containing parameter values generated variables simulated datasets","code":""},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate dataset — SimData","text":"hfun = 1: nonlinear function first predictor hfun = 2: linear function first two predictors product term hfun = 3: nonlinear nonadditive function first two predictor variables","code":""},{"path":"https://sngao.github.io/bkmr/reference/SimData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate dataset — SimData","text":"","code":"set.seed(5) dat <- SimData()"},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Single Variable Interaction Summaries — SingVarIntSummaries","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"Compare single-predictor health risks predictors Z fixed specific quantile predictors Z fixed second specific quantile.","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"","code":"SingVarIntSummaries(   fit,   y = NULL,   Z = NULL,   X = NULL,   which.z = 1:ncol(Z),   qs.diff = c(0.25, 0.75),   qs.fixed = c(0.25, 0.75),   method = \"approx\",   sel = NULL,   z.names = colnames(Z),   ... )"},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. .z vector indicating variables (columns Z) summary computed qs.diff vector indicating two quantiles compute single-predictor risk summary qs.fixed vector indicating two quantiles fix remaining exposures Z method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details sel logical expression indicating samples keep; defaults keeping second half samples z.names optional vector names columns z ... arguments pass prediction function","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"data frame containing (posterior mean) estimate posterior standard deviation single-predictor risk measures","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"method == \"approx\", argument sel defaults second half MCMC iterations. method == \"exact\", argument sel defaults keeping every 10 iterations dropping first 50% samples, results fewer 100 iterations, 100 iterations kept guided examples additional information, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarIntSummaries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single Variable Interaction Summaries — SingVarIntSummaries","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00483 secs elapsed) #> Iteration: 20 (20% completed; 0.01008 secs elapsed) #> Iteration: 30 (30% completed; 0.01533 secs elapsed) #> Iteration: 40 (40% completed; 0.02129 secs elapsed) #> Iteration: 50 (50% completed; 0.02658 secs elapsed) #> Iteration: 60 (60% completed; 0.03214 secs elapsed) #> Iteration: 70 (70% completed; 0.03795 secs elapsed) #> Iteration: 80 (80% completed; 0.04394 secs elapsed) #> Iteration: 90 (90% completed; 0.05681 secs elapsed) #> Iteration: 100 (100% completed; 0.06202 secs elapsed)  risks.int <- SingVarIntSummaries(fit = fitkm, method = \"exact\")"},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Single Variable Risk Summaries — SingVarRiskSummaries","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"Compute summaries risks associated change single variable Z single level (quantile) second level (quantile), variables Z fixed specific level (quantile)","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"","code":"SingVarRiskSummaries(   fit,   y = NULL,   Z = NULL,   X = NULL,   which.z = 1:ncol(Z),   qs.diff = c(0.25, 0.75),   q.fixed = c(0.25, 0.5, 0.75),   method = \"approx\",   sel = NULL,   z.names = colnames(Z),   ... )"},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"fit object containing results returned kmbayes function y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. .z vector indicating variables (columns Z) summary computed qs.diff vector indicating two quantiles q_1 q_2 compute h(z_{q2}) - h(z_{q1}) q.fixed vector quantiles fix remaining predictors Z method method obtaining posterior summaries vector new points. Options \"approx\" \"exact\"; defaults \"approx\", faster particularly large datasets; see details sel logical expression indicating samples keep; defaults keeping second half samples z.names optional vector names columns z ... arguments pass prediction function","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"data frame containing (posterior mean) estimate posterior standard deviation single-predictor risk measures","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"method == \"approx\", argument sel defaults second half MCMC iterations. method == \"exact\", argument sel defaults keeping every 10 iterations dropping first 50% samples, results fewer 100 iterations, 100 iterations kept guided examples additional information, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/SingVarRiskSummaries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single Variable Risk Summaries — SingVarRiskSummaries","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00488 secs elapsed) #> Iteration: 20 (20% completed; 0.01012 secs elapsed) #> Iteration: 30 (30% completed; 0.01526 secs elapsed) #> Iteration: 40 (40% completed; 0.02047 secs elapsed) #> Iteration: 50 (50% completed; 0.02558 secs elapsed) #> Iteration: 60 (60% completed; 0.03112 secs elapsed) #> Iteration: 70 (70% completed; 0.03648 secs elapsed) #> Iteration: 80 (80% completed; 0.0417 secs elapsed) #> Iteration: 90 (90% completed; 0.04699 secs elapsed) #> Iteration: 100 (100% completed; 0.05217 secs elapsed)  risks.singvar <- SingVarRiskSummaries(fit = fitkm, method = \"exact\")"},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Trace plot — TracePlot","title":"Trace plot — TracePlot","text":"Trace plot","code":""},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trace plot — TracePlot","text":"","code":"TracePlot(   fit,   par,   comp = 1,   sel = NULL,   main = \"\",   xlab = \"iteration\",   ylab = \"parameter value\",   ... )"},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trace plot — TracePlot","text":"fit object containing results returned kmbayes function par parameter plot comp component parameter vector plot sel logical expression indicating samples keep; defaults keeping second half samples main title xlab x axis label ylab y axis label ... arguments pass onto plotting function","code":""},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trace plot — TracePlot","text":"return value, generates plot","code":""},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trace plot — TracePlot","text":"guided examples, go https://jenfb.github.io/bkmr/overview.html","code":""},{"path":"https://sngao.github.io/bkmr/reference/TracePlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trace plot — TracePlot","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00522 secs elapsed) #> Iteration: 20 (20% completed; 0.01053 secs elapsed) #> Iteration: 30 (30% completed; 0.01593 secs elapsed) #> Iteration: 40 (40% completed; 0.0213 secs elapsed) #> Iteration: 50 (50% completed; 0.03381 secs elapsed) #> Iteration: 60 (60% completed; 0.03897 secs elapsed) #> Iteration: 70 (70% completed; 0.04405 secs elapsed) #> Iteration: 80 (80% completed; 0.0492 secs elapsed) #> Iteration: 90 (90% completed; 0.05434 secs elapsed) #> Iteration: 100 (100% completed; 0.05971 secs elapsed)  TracePlot(fit = fitkm, par = \"beta\")  TracePlot(fit = fitkm, par = \"sigsq.eps\")  TracePlot(fit = fitkm, par = \"r\", comp = 1)"},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Bayesian kernel machine regression — kmbayes","title":"Fit Bayesian kernel machine regression — kmbayes","text":"Fits Bayesian kernel machine regression (BKMR) model using Markov chain Monte Carlo (MCMC) methods.","code":""},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Bayesian kernel machine regression — kmbayes","text":"","code":"kmbayes(   y,   Z,   X = NULL,   iter = 1000,   family = \"gaussian\",   id = NULL,   verbose = TRUE,   Znew = NULL,   starting.values = NULL,   control.params = NULL,   varsel = FALSE,   groups = NULL,   knots = NULL,   ztest = NULL,   rmethod = \"varying\",   est.h = FALSE )"},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Bayesian kernel machine regression — kmbayes","text":"y vector outcome data length n. Z n--M matrix predictor variables included h function. row represents observation column represents predictor. X n--K matrix covariate data row represents observation column represents covariate. contain intercept column. iter number iterations run sampler family description error distribution link function used model. Currently implemented gaussian binomial families. id optional vector (length n) grouping factors fitting model random intercept. NULL random intercept included. verbose TRUE FALSE: flag indicating whether print intermediate diagnostic information model fitting. Znew optional matrix new predictor values predict h, row represents new observation. slow model fitting, can done post-processing step using SamplePred starting.values list starting values parameter. specified default values chosen. control.params list parameters specifying prior distributions tuning parameters MCMC algorithm. specified default values chosen. varsel TRUE FALSE: indicator whether conduct variable selection Z variables h groups optional vector (length M) group indicators fitting hierarchical variable selection varsel=TRUE. varsel=TRUE without group specification, component-wise variable selections performed. knots optional matrix knot locations implementing Gaussian predictive process Banerjee et al. (2008). Currently implemented models without random intercept. ztest optional vector indicating variables Z conduct variable selection (remaining variables forced model). rmethod predictors forced h function, method sampling r[m] values. Takes value 'varying' allow separate r[m] predictor; 'equal' force r[m] predictor; 'fixed' fix r[m] starting values est.h TRUE FALSE: indicator whether sample posterior distribution subject-specific effects h_i within main sampler. slow model fitting.","code":""},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit Bayesian kernel machine regression — kmbayes","text":"object class \"bkmrfit\" (containing posterior samples model fit), associated methods: print (.e., print.bkmrfit) summary (.e., summary.bkmrfit)","code":""},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit Bayesian kernel machine regression — kmbayes","text":"Bobb, JF, Valeri L, Claus Henn B, Christiani DC, Wright RO, Mazumdar M, Godleski JJ, Coull BA (2015). Bayesian Kernel Machine Regression Estimating Health Effects Multi-Pollutant Mixtures. Biostatistics 16, . 3: 493-508. Banerjee S, Gelfand AE, Finley AO, Sang H (2008). Gaussian predictive process models large spatial data sets. Journal Royal Statistical Society: Series B (Statistical Methodology), 70(4), 825-848.","code":""},{"path":[]},{"path":"https://sngao.github.io/bkmr/reference/kmbayes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Bayesian kernel machine regression — kmbayes","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00527 secs elapsed) #> Iteration: 20 (20% completed; 0.01053 secs elapsed) #> Iteration: 30 (30% completed; 0.01586 secs elapsed) #> Iteration: 40 (40% completed; 0.02133 secs elapsed) #> Iteration: 50 (50% completed; 0.02665 secs elapsed) #> Iteration: 60 (60% completed; 0.03189 secs elapsed) #> Iteration: 70 (70% completed; 0.03704 secs elapsed) #> Iteration: 80 (80% completed; 0.04221 secs elapsed) #> Iteration: 90 (90% completed; 0.05511 secs elapsed) #> Iteration: 100 (100% completed; 0.06052 secs elapsed)"},{"path":"https://sngao.github.io/bkmr/reference/print.bkmrfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print basic summary of BKMR model fit — print.bkmrfit","title":"Print basic summary of BKMR model fit — print.bkmrfit","text":"print method class \"bkmrfit\"","code":""},{"path":"https://sngao.github.io/bkmr/reference/print.bkmrfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print basic summary of BKMR model fit — print.bkmrfit","text":"","code":"# S3 method for bkmrfit print(x, digits = 5, ...)"},{"path":"https://sngao.github.io/bkmr/reference/print.bkmrfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print basic summary of BKMR model fit — print.bkmrfit","text":"x object class \"bkmrfit\" digits number digits show printing ... arguments passed methods.","code":""},{"path":"https://sngao.github.io/bkmr/reference/print.bkmrfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print basic summary of BKMR model fit — print.bkmrfit","text":"return value, prints basic summary fit console","code":""},{"path":"https://sngao.github.io/bkmr/reference/print.bkmrfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print basic summary of BKMR model fit — print.bkmrfit","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.00506 secs elapsed) #> Iteration: 20 (20% completed; 0.01045 secs elapsed) #> Iteration: 30 (30% completed; 0.01564 secs elapsed) #> Iteration: 40 (40% completed; 0.02076 secs elapsed) #> Iteration: 50 (50% completed; 0.02603 secs elapsed) #> Iteration: 60 (60% completed; 0.03134 secs elapsed) #> Iteration: 70 (70% completed; 0.03648 secs elapsed) #> Iteration: 80 (80% completed; 0.04165 secs elapsed) #> Iteration: 90 (90% completed; 0.04697 secs elapsed) #> Iteration: 100 (100% completed; 0.05219 secs elapsed) fitkm #> Fitted object of class 'bkmrfit' #> Iterations: 100  #> Outcome family: gaussian   #> Model fit on: 2023-12-07 08:29:45"},{"path":"https://sngao.github.io/bkmr/reference/summary.bkmrfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing BKMR model fits — summary.bkmrfit","title":"Summarizing BKMR model fits — summary.bkmrfit","text":"summary method class \"bkmrfit\"","code":""},{"path":"https://sngao.github.io/bkmr/reference/summary.bkmrfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing BKMR model fits — summary.bkmrfit","text":"","code":"# S3 method for bkmrfit summary(   object,   q = c(0.025, 0.975),   digits = 5,   show_ests = TRUE,   show_MH = TRUE,   ... )"},{"path":"https://sngao.github.io/bkmr/reference/summary.bkmrfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing BKMR model fits — summary.bkmrfit","text":"object object class \"bkmrfit\" q quantiles posterior distribution show digits number digits show printing show_ests logical; TRUE, prints summary statistics posterior distribution show_MH logical; TRUE, prints acceptance rates Metropolis-Hastings algorithm ... arguments passed methods.","code":""},{"path":"https://sngao.github.io/bkmr/reference/summary.bkmrfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing BKMR model fits — summary.bkmrfit","text":"return value, prints detailed summary fit console","code":""},{"path":"https://sngao.github.io/bkmr/reference/summary.bkmrfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing BKMR model fits — summary.bkmrfit","text":"","code":"## First generate dataset set.seed(111) dat <- SimData(n = 50, M = 4) y <- dat$y Z <- dat$Z X <- dat$X  ## Fit model with component-wise variable selection ## Using only 100 iterations to make example run quickly ## Typically should use a large number of iterations for inference set.seed(111) fitkm <- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE) #> Iteration: 10 (10% completed; 0.01271 secs elapsed) #> Iteration: 20 (20% completed; 0.01791 secs elapsed) #> Iteration: 30 (30% completed; 0.02325 secs elapsed) #> Iteration: 40 (40% completed; 0.02842 secs elapsed) #> Iteration: 50 (50% completed; 0.03356 secs elapsed) #> Iteration: 60 (60% completed; 0.03869 secs elapsed) #> Iteration: 70 (70% completed; 0.04403 secs elapsed) #> Iteration: 80 (80% completed; 0.04919 secs elapsed) #> Iteration: 90 (90% completed; 0.05466 secs elapsed) #> Iteration: 100 (100% completed; 0.05993 secs elapsed) summary(fitkm) #> Fitted object of class 'bkmrfit' #> Iterations: 100  #> Outcome family: gaussian   #> Model fit on: 2023-12-07 08:29:46  #> Running time:  0.06008 secs  #>  #> Acceptance rates for Metropolis-Hastings algorithm: #>               param      rate #> 1            lambda 0.1010101 #> 2 r/delta (overall) 0.5252525 #> 3 r/delta  (move 1) 0.3255814 #> 4 r/delta  (move 2) 0.6785714 #>  #> Parameter estimates (based on iterations 51-100): #>       param    mean      sd   q_2.5  q_97.5 #> 1      beta 1.88931 0.08176 1.72388 2.04660 #> 2 sigsq.eps 0.50905 0.10964 0.33635 0.74966 #> 3        r1 0.76502 0.13487 0.49609 0.94809 #> 4        r2 1.22987 0.08528 1.09164 1.36021 #> 5        r3 0.00000 0.00000 0.00000 0.00000 #> 6        r4 0.00606 0.01004 0.00000 0.02415 #> 7    lambda 4.56075 0.55773 4.17943 6.14513 #>  #> Posterior inclusion probabilities: #>   variable  PIP #> 1       z1 1.00 #> 2       z2 1.00 #> 3       z3 0.00 #> 4       z4 0.28 #> NULL"},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bkmr-022","dir":"Changelog","previous_headings":"","what":"bkmr 0.2.2","title":"bkmr 0.2.2","text":"CRAN release: 2022-03-28","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bug-fixes-0-2-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"bkmr 0.2.2","text":"Corrected code produced warning length > 1 coercion logical Update functions use deprecated functions dplyr package","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"minor-changes-0-2-2","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"bkmr 0.2.2","text":"longer export following functions: CalcGroupPIPs, CalcWithinGroupPIPs, CalcPIPs typically calculated using function ExtractPIPs ComputePostmeanHnew.approx ComputePostmeanHnew.exact typically calculated using function ComputePostmeanHnew set_verbose_opts called internally Expanded function documentation adding example code","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bkmr-021","dir":"Changelog","previous_headings":"","what":"bkmr 0.2.1","title":"bkmr 0.2.1","text":"CRAN release: 2022-03-04","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bug-fixes-0-2-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"bkmr 0.2.1","text":"allowable values starting parameter r[m] parameters updated follows longer truncated single value (varsel = FALSE rmethod = \"varying\") can equal 0 (varsel = TRUE) Error longer generated starting values h.hat positive checking class object, use inherits() instead class()","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bkmr-020","dir":"Changelog","previous_headings":"","what":"bkmr 0.2.0","title":"bkmr 0.2.0","text":"CRAN release: 2017-03-24","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"major-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"bkmr 0.2.0","text":"Added ability binomial outcome family implementing probit regression within kmbayes() Removed computation subject-specific effects h[] within kmbayes(), always desired, greatly slows model fitting still done setting option est.h = TRUE kmbayes function posterior samples h[] can now obtained via post-processing SamplePred function; alternatively, posterior summaries (mean, variance) can obtained via post-processing ComputePostmeanHnew function Added ability use exact estimates posterior mean variance specifying argument method = 'exact' within post-processing functions (e.g., OverallRiskSummaries(), PredictorResponseUnivar())","code":""},{"path":"https://sngao.github.io/bkmr/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"bkmr 0.2.0","text":"Fixed PredictorResponseBivarLevels() argument both_pairs = TRUE (#4)","code":""}]
